{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ea63187f60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "The `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TO-DO: need to init as a numpy array \n",
    "    norm_arr = []\n",
    "    for arr in x:\n",
    "        # better ways to do this other than dividing the max?\n",
    "        arr = arr / np.amax(arr)\n",
    "        norm_arr.append(arr)\n",
    "    # can't we just use tf.image.per_image_standardization?\n",
    "    return np.array(norm_arr)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0],  image_shape[1], image_shape[2]), name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    input_shape = x_tensor.get_shape().as_list()\n",
    "    weights = tf.Variable(tf.truncated_normal((conv_ksize[0], conv_ksize[1], input_shape[3], conv_num_outputs)))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor, weights, [1, conv_strides[0], conv_strides[1], 1], 'SAME')\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    pool = tf.nn.max_pool(conv, [1, pool_ksize[0], pool_ksize[1], 1], [1, pool_strides[0], pool_strides[1], 1], 'SAME')\n",
    "    \n",
    "    return pool\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    input_shape = x_tensor.get_shape().as_list()\n",
    "    flatten_image = input_shape[1]*input_shape[2]*input_shape[3]\n",
    "    \n",
    "    # use -1 to infer the shape\n",
    "    flatten_layer = tf.reshape(x_tensor, [-1, flatten_image])\n",
    "\n",
    "    return flatten_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    input_shape = x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.random_normal([input_shape[1], num_outputs]))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    \n",
    "    fully_conn = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    fully_conn = tf.nn.relu(fully_conn)\n",
    "\n",
    "    return fully_conn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    input_shape = x_tensor.get_shape().as_list()\n",
    "    weight = tf.Variable(tf.random_normal([input_shape[1], num_outputs]))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    # Tensor(\"Placeholder_32:0\", shape=(?, 32, 32, 5), dtype=float32) 10 (2, 2) (4, 4) (2, 2) (2, 2)\n",
    "    x = conv2d_maxpool(x, 10, (2, 2), (4, 4), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 10, (2, 2), (4, 4), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 10, (2, 2), (4, 4), (2, 2), (2, 2))\n",
    "    \n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "    \n",
    "    \n",
    "    #keep_prob = keep_prob.get_shape().as_list()\n",
    "    # print(keep_prob.get_shape())\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x, 40)\n",
    "    #x = tf.nn.dropout(x, 0.5)\n",
    "    x = fully_conn(x, 40)\n",
    "    #x = tf.nn.dropout(x, 0.5)\n",
    "    \n",
    "    \n",
    "    # Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    x = output(x, 10)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 1000\n",
    "batch_size = 1024\n",
    "keep_probability = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:  1139.7522 Validation Accuracy: 0.105400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   787.2209 Validation Accuracy: 0.100400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   499.5923 Validation Accuracy: 0.094000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   349.4072 Validation Accuracy: 0.103800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   279.2068 Validation Accuracy: 0.092200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   214.7446 Validation Accuracy: 0.119800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   177.1291 Validation Accuracy: 0.106600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   151.3334 Validation Accuracy: 0.112000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   124.1798 Validation Accuracy: 0.120400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   109.6115 Validation Accuracy: 0.121800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   100.8999 Validation Accuracy: 0.125600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    98.6264 Validation Accuracy: 0.123400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    94.7259 Validation Accuracy: 0.123600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    92.0473 Validation Accuracy: 0.129800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    89.4972 Validation Accuracy: 0.126600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    87.2717 Validation Accuracy: 0.127000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    84.8989 Validation Accuracy: 0.127600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    82.2346 Validation Accuracy: 0.126800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    79.0863 Validation Accuracy: 0.125600\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    74.9611 Validation Accuracy: 0.127600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    69.6680 Validation Accuracy: 0.125200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    64.8250 Validation Accuracy: 0.128800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    61.6383 Validation Accuracy: 0.130200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    59.0219 Validation Accuracy: 0.131800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    56.6275 Validation Accuracy: 0.130800\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    54.5455 Validation Accuracy: 0.130000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    52.5541 Validation Accuracy: 0.130200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    50.6308 Validation Accuracy: 0.129600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    48.7297 Validation Accuracy: 0.126600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    47.0250 Validation Accuracy: 0.126800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    45.6329 Validation Accuracy: 0.129000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    44.2518 Validation Accuracy: 0.131400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    42.7697 Validation Accuracy: 0.130600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    41.2298 Validation Accuracy: 0.134400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    39.6854 Validation Accuracy: 0.137000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    38.1331 Validation Accuracy: 0.133600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    36.4516 Validation Accuracy: 0.135800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    34.7029 Validation Accuracy: 0.136400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    32.8231 Validation Accuracy: 0.136000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    30.8183 Validation Accuracy: 0.139000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    28.8516 Validation Accuracy: 0.136000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    27.1147 Validation Accuracy: 0.133200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    25.8554 Validation Accuracy: 0.136000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    24.8839 Validation Accuracy: 0.135200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    23.9217 Validation Accuracy: 0.137600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    23.0658 Validation Accuracy: 0.138600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    22.2430 Validation Accuracy: 0.138800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    21.4913 Validation Accuracy: 0.140000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    20.7410 Validation Accuracy: 0.141000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    20.0378 Validation Accuracy: 0.143400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    19.3879 Validation Accuracy: 0.144600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    18.7635 Validation Accuracy: 0.142800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    18.1483 Validation Accuracy: 0.142000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    17.6088 Validation Accuracy: 0.139000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    17.0790 Validation Accuracy: 0.137800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    16.5807 Validation Accuracy: 0.139000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    16.0507 Validation Accuracy: 0.136600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    15.5253 Validation Accuracy: 0.136200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    15.0578 Validation Accuracy: 0.137000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    14.5604 Validation Accuracy: 0.133400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    14.0740 Validation Accuracy: 0.135000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    13.6246 Validation Accuracy: 0.136600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    13.2347 Validation Accuracy: 0.138600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    12.8925 Validation Accuracy: 0.138200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    12.4731 Validation Accuracy: 0.136400\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    12.0764 Validation Accuracy: 0.136000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    11.7857 Validation Accuracy: 0.126800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    11.6782 Validation Accuracy: 0.133600\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    11.2897 Validation Accuracy: 0.137000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    11.7005 Validation Accuracy: 0.127000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    10.9308 Validation Accuracy: 0.137600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    10.8138 Validation Accuracy: 0.132400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    11.2298 Validation Accuracy: 0.126800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    10.4242 Validation Accuracy: 0.135600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    11.2090 Validation Accuracy: 0.130000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    12.6843 Validation Accuracy: 0.138600\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    11.9474 Validation Accuracy: 0.142800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    11.4583 Validation Accuracy: 0.132800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    10.9654 Validation Accuracy: 0.144800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     9.4774 Validation Accuracy: 0.122400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     9.7889 Validation Accuracy: 0.147400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     9.2171 Validation Accuracy: 0.120800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     9.0496 Validation Accuracy: 0.141800\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     8.9531 Validation Accuracy: 0.121800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     8.5091 Validation Accuracy: 0.133200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     8.3448 Validation Accuracy: 0.137200\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     9.3462 Validation Accuracy: 0.136800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     9.8977 Validation Accuracy: 0.118000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     9.9341 Validation Accuracy: 0.135200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     8.7092 Validation Accuracy: 0.126000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     8.6934 Validation Accuracy: 0.112600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     7.4444 Validation Accuracy: 0.128400\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     7.5816 Validation Accuracy: 0.150000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     8.2778 Validation Accuracy: 0.136200\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     8.6744 Validation Accuracy: 0.143000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     7.3779 Validation Accuracy: 0.150200\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     7.3613 Validation Accuracy: 0.136200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     7.4020 Validation Accuracy: 0.125000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     6.8225 Validation Accuracy: 0.137000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     7.8861 Validation Accuracy: 0.120000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     6.7726 Validation Accuracy: 0.158600\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     6.7224 Validation Accuracy: 0.137800\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     6.9142 Validation Accuracy: 0.135000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     7.9980 Validation Accuracy: 0.142400\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     6.2278 Validation Accuracy: 0.152400\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     6.6622 Validation Accuracy: 0.146200\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     8.3523 Validation Accuracy: 0.122000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     7.3878 Validation Accuracy: 0.143200\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     5.7516 Validation Accuracy: 0.146000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     5.2822 Validation Accuracy: 0.172600\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     6.4750 Validation Accuracy: 0.165600\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     7.0665 Validation Accuracy: 0.130600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     6.6630 Validation Accuracy: 0.146400\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     9.1321 Validation Accuracy: 0.132000\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     8.2763 Validation Accuracy: 0.104200\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     5.4511 Validation Accuracy: 0.167200\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     5.2558 Validation Accuracy: 0.164600\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     5.2044 Validation Accuracy: 0.131600\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     4.6603 Validation Accuracy: 0.133600\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     7.4182 Validation Accuracy: 0.149600\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     7.8763 Validation Accuracy: 0.123400\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     8.8154 Validation Accuracy: 0.128400\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     7.8725 Validation Accuracy: 0.153200\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     6.5429 Validation Accuracy: 0.138400\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     5.5648 Validation Accuracy: 0.164800\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     5.9679 Validation Accuracy: 0.151800\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     7.8820 Validation Accuracy: 0.116200\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     6.2325 Validation Accuracy: 0.138200\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     5.2287 Validation Accuracy: 0.132200\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     7.6408 Validation Accuracy: 0.135200\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     6.7761 Validation Accuracy: 0.126200\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     6.0921 Validation Accuracy: 0.171400\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     4.5653 Validation Accuracy: 0.166200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     4.9917 Validation Accuracy: 0.118600\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     5.2260 Validation Accuracy: 0.120200\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     5.0831 Validation Accuracy: 0.119200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     5.9942 Validation Accuracy: 0.158600\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     4.9610 Validation Accuracy: 0.162600\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     4.4518 Validation Accuracy: 0.126000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     4.6227 Validation Accuracy: 0.116600\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     5.2252 Validation Accuracy: 0.105800\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     5.3991 Validation Accuracy: 0.125800\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     5.7830 Validation Accuracy: 0.119200\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     5.3429 Validation Accuracy: 0.128400\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     5.2969 Validation Accuracy: 0.117200\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     4.7852 Validation Accuracy: 0.129400\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     4.9777 Validation Accuracy: 0.110200\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     3.9055 Validation Accuracy: 0.151400\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     4.2767 Validation Accuracy: 0.162800\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     4.8103 Validation Accuracy: 0.119600\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     4.8382 Validation Accuracy: 0.154600\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     4.5872 Validation Accuracy: 0.133000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     4.5093 Validation Accuracy: 0.114800\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     4.9367 Validation Accuracy: 0.171400\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     4.9635 Validation Accuracy: 0.124400\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     4.4834 Validation Accuracy: 0.155000\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     5.9719 Validation Accuracy: 0.111000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     5.5580 Validation Accuracy: 0.112400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     5.6098 Validation Accuracy: 0.142000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     4.1909 Validation Accuracy: 0.130600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     4.8373 Validation Accuracy: 0.127000\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     4.6933 Validation Accuracy: 0.118400\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     5.0673 Validation Accuracy: 0.113200\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     5.7898 Validation Accuracy: 0.141000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     5.8334 Validation Accuracy: 0.136200\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     5.8198 Validation Accuracy: 0.122800\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     5.6053 Validation Accuracy: 0.111400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     5.5875 Validation Accuracy: 0.123200\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     4.3875 Validation Accuracy: 0.139400\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     4.9546 Validation Accuracy: 0.161000\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     4.7583 Validation Accuracy: 0.157200\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     4.6892 Validation Accuracy: 0.134000\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     4.3474 Validation Accuracy: 0.122800\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     4.0552 Validation Accuracy: 0.129000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     3.2040 Validation Accuracy: 0.172000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     3.1406 Validation Accuracy: 0.163600\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     3.0195 Validation Accuracy: 0.174400\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     2.9646 Validation Accuracy: 0.164800\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     3.0418 Validation Accuracy: 0.145200\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     3.5248 Validation Accuracy: 0.146800\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     3.5433 Validation Accuracy: 0.157200\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     3.4478 Validation Accuracy: 0.137000\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     3.7193 Validation Accuracy: 0.120800\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     5.3596 Validation Accuracy: 0.123200\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     3.5667 Validation Accuracy: 0.134800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     4.6789 Validation Accuracy: 0.133400\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     6.3268 Validation Accuracy: 0.152600\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     4.2311 Validation Accuracy: 0.152600\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     3.6468 Validation Accuracy: 0.131600\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     6.0504 Validation Accuracy: 0.144000\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     7.1660 Validation Accuracy: 0.111000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     6.7240 Validation Accuracy: 0.113800\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     4.9019 Validation Accuracy: 0.165600\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     4.9178 Validation Accuracy: 0.130400\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     4.7138 Validation Accuracy: 0.112600\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     4.7939 Validation Accuracy: 0.125000\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     5.9992 Validation Accuracy: 0.132400\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     4.8240 Validation Accuracy: 0.164000\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     5.2237 Validation Accuracy: 0.141400\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     4.7782 Validation Accuracy: 0.145200\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     4.4452 Validation Accuracy: 0.133800\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     3.5890 Validation Accuracy: 0.143000\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     4.7435 Validation Accuracy: 0.173800\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     3.4423 Validation Accuracy: 0.140000\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     3.6966 Validation Accuracy: 0.152200\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     3.1571 Validation Accuracy: 0.155800\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     3.2674 Validation Accuracy: 0.161400\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     4.2625 Validation Accuracy: 0.151000\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     3.7514 Validation Accuracy: 0.124800\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     3.2308 Validation Accuracy: 0.160000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     3.2881 Validation Accuracy: 0.121000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     3.1452 Validation Accuracy: 0.144000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     3.3173 Validation Accuracy: 0.163600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     3.2128 Validation Accuracy: 0.146800\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     2.8800 Validation Accuracy: 0.156200\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     2.8831 Validation Accuracy: 0.162000\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     2.7798 Validation Accuracy: 0.176600\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     2.8272 Validation Accuracy: 0.175600\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     2.7776 Validation Accuracy: 0.172400\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     2.8031 Validation Accuracy: 0.142000\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     2.7883 Validation Accuracy: 0.154000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     2.7793 Validation Accuracy: 0.140000\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     2.6887 Validation Accuracy: 0.155000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     2.7083 Validation Accuracy: 0.155200\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     2.7117 Validation Accuracy: 0.157800\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     2.7166 Validation Accuracy: 0.164600\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     2.7495 Validation Accuracy: 0.156800\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     3.1439 Validation Accuracy: 0.149600\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     3.9347 Validation Accuracy: 0.144800\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     3.4355 Validation Accuracy: 0.132400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     4.6232 Validation Accuracy: 0.147200\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     3.9061 Validation Accuracy: 0.177400\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     8.4978 Validation Accuracy: 0.123400\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     6.9289 Validation Accuracy: 0.152200\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     5.3036 Validation Accuracy: 0.123600\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     4.9922 Validation Accuracy: 0.116400\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     4.6115 Validation Accuracy: 0.133600\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     5.7383 Validation Accuracy: 0.104800\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     4.1135 Validation Accuracy: 0.117400\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     3.2381 Validation Accuracy: 0.181600\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     3.2910 Validation Accuracy: 0.158200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     3.0687 Validation Accuracy: 0.175800\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     4.0193 Validation Accuracy: 0.159400\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     4.5217 Validation Accuracy: 0.150800\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     4.4826 Validation Accuracy: 0.148000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     3.8040 Validation Accuracy: 0.143800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     3.0944 Validation Accuracy: 0.146000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     2.8350 Validation Accuracy: 0.161600\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     2.8178 Validation Accuracy: 0.160600\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     2.7399 Validation Accuracy: 0.153400\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     2.9893 Validation Accuracy: 0.149800\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     3.2119 Validation Accuracy: 0.137200\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     2.7942 Validation Accuracy: 0.153000\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     2.9927 Validation Accuracy: 0.151200\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     3.3260 Validation Accuracy: 0.112200\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     3.0578 Validation Accuracy: 0.146000\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     2.8667 Validation Accuracy: 0.142000\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     2.7248 Validation Accuracy: 0.148800\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     3.1837 Validation Accuracy: 0.147000\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     3.2127 Validation Accuracy: 0.139600\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     5.4952 Validation Accuracy: 0.140000\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     7.2448 Validation Accuracy: 0.151000\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     7.8338 Validation Accuracy: 0.127200\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     8.0499 Validation Accuracy: 0.114200\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     7.4365 Validation Accuracy: 0.101400\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     4.1205 Validation Accuracy: 0.149000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     5.4681 Validation Accuracy: 0.139600\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     5.0627 Validation Accuracy: 0.132400\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     4.2753 Validation Accuracy: 0.116400\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     3.3522 Validation Accuracy: 0.140000\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     4.0911 Validation Accuracy: 0.101200\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     3.4845 Validation Accuracy: 0.124200\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     3.1094 Validation Accuracy: 0.158400\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     2.8958 Validation Accuracy: 0.155000\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     3.1295 Validation Accuracy: 0.147000\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     2.7543 Validation Accuracy: 0.130800\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     2.6709 Validation Accuracy: 0.151800\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     2.7489 Validation Accuracy: 0.155600\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     2.7083 Validation Accuracy: 0.151000\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     2.7062 Validation Accuracy: 0.162200\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     2.6631 Validation Accuracy: 0.157200\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     2.6560 Validation Accuracy: 0.146600\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     2.6921 Validation Accuracy: 0.154200\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     2.6773 Validation Accuracy: 0.155600\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     2.6092 Validation Accuracy: 0.147000\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     2.5868 Validation Accuracy: 0.147800\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     2.5618 Validation Accuracy: 0.161800\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     2.6414 Validation Accuracy: 0.146800\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     2.5496 Validation Accuracy: 0.159000\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     3.4683 Validation Accuracy: 0.124200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     8.8468 Validation Accuracy: 0.107400\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     8.0623 Validation Accuracy: 0.137600\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     8.4905 Validation Accuracy: 0.135800\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     9.8229 Validation Accuracy: 0.107400\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     6.2337 Validation Accuracy: 0.108400\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     7.2806 Validation Accuracy: 0.154000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     4.9540 Validation Accuracy: 0.132200\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     5.9068 Validation Accuracy: 0.137000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     4.3735 Validation Accuracy: 0.116400\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     3.6665 Validation Accuracy: 0.169200\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     3.7673 Validation Accuracy: 0.172600\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     4.0245 Validation Accuracy: 0.139800\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     3.4981 Validation Accuracy: 0.165000\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     4.0239 Validation Accuracy: 0.164400\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     3.0948 Validation Accuracy: 0.153200\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     3.9033 Validation Accuracy: 0.167600\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     4.2034 Validation Accuracy: 0.164400\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     4.6728 Validation Accuracy: 0.131400\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     4.7399 Validation Accuracy: 0.110200\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     3.8237 Validation Accuracy: 0.135400\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     4.2239 Validation Accuracy: 0.109000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     3.2603 Validation Accuracy: 0.136800\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     2.8409 Validation Accuracy: 0.158000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     2.7907 Validation Accuracy: 0.157600\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     2.7243 Validation Accuracy: 0.159000\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     2.7064 Validation Accuracy: 0.155400\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     2.8998 Validation Accuracy: 0.154600\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     2.9707 Validation Accuracy: 0.154600\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     2.7580 Validation Accuracy: 0.125800\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     2.8478 Validation Accuracy: 0.131400\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     3.1801 Validation Accuracy: 0.162000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     3.0414 Validation Accuracy: 0.159200\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     7.0772 Validation Accuracy: 0.118400\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     9.4391 Validation Accuracy: 0.125000\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     7.8080 Validation Accuracy: 0.108800\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     5.5061 Validation Accuracy: 0.135000\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     4.6252 Validation Accuracy: 0.126000\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     3.9033 Validation Accuracy: 0.133800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     3.4236 Validation Accuracy: 0.139800\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     2.9681 Validation Accuracy: 0.153600\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     2.9564 Validation Accuracy: 0.166800\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     3.1103 Validation Accuracy: 0.152000\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     2.9065 Validation Accuracy: 0.150800\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     3.3236 Validation Accuracy: 0.140400\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     3.5803 Validation Accuracy: 0.132600\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     3.4071 Validation Accuracy: 0.139400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     3.1445 Validation Accuracy: 0.148600\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     3.6669 Validation Accuracy: 0.137600\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     3.3170 Validation Accuracy: 0.114800\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     4.0577 Validation Accuracy: 0.129000\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     4.8425 Validation Accuracy: 0.106400\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     4.7492 Validation Accuracy: 0.141000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     6.9341 Validation Accuracy: 0.122200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     6.8243 Validation Accuracy: 0.112200\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     4.3304 Validation Accuracy: 0.139800\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     3.5024 Validation Accuracy: 0.159600\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     3.1628 Validation Accuracy: 0.144000\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     2.8927 Validation Accuracy: 0.148600\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     2.7610 Validation Accuracy: 0.156200\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     2.7534 Validation Accuracy: 0.161800\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     2.6572 Validation Accuracy: 0.156000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     2.6476 Validation Accuracy: 0.159200\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     2.6091 Validation Accuracy: 0.161800\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     2.5675 Validation Accuracy: 0.158400\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     2.5631 Validation Accuracy: 0.160200\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     2.5767 Validation Accuracy: 0.163800\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     2.5951 Validation Accuracy: 0.154800\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     2.6299 Validation Accuracy: 0.143400\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     2.5689 Validation Accuracy: 0.156600\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     3.2714 Validation Accuracy: 0.152800\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     3.8502 Validation Accuracy: 0.110200\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     8.1795 Validation Accuracy: 0.098000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     7.9192 Validation Accuracy: 0.119800\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     8.7883 Validation Accuracy: 0.113200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     7.6624 Validation Accuracy: 0.138400\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     6.5338 Validation Accuracy: 0.137400\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     4.4285 Validation Accuracy: 0.119800\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     4.0818 Validation Accuracy: 0.149000\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     4.7583 Validation Accuracy: 0.119800\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     3.6912 Validation Accuracy: 0.137600\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     3.6209 Validation Accuracy: 0.149800\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     4.1271 Validation Accuracy: 0.106800\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     3.7862 Validation Accuracy: 0.108200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     3.4848 Validation Accuracy: 0.135200\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     3.1466 Validation Accuracy: 0.147800\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     3.1829 Validation Accuracy: 0.157000\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     3.2603 Validation Accuracy: 0.160400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     4.2303 Validation Accuracy: 0.145200\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     4.0915 Validation Accuracy: 0.109400\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     2.9676 Validation Accuracy: 0.146200\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     3.4674 Validation Accuracy: 0.150200\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     3.3671 Validation Accuracy: 0.151600\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     3.3127 Validation Accuracy: 0.118000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     2.7298 Validation Accuracy: 0.147000\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     3.2074 Validation Accuracy: 0.156600\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     3.8989 Validation Accuracy: 0.114800\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     4.4714 Validation Accuracy: 0.131000\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     4.7930 Validation Accuracy: 0.138200\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     4.5626 Validation Accuracy: 0.130400\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     4.6957 Validation Accuracy: 0.154200\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     4.4222 Validation Accuracy: 0.111800\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     5.8966 Validation Accuracy: 0.152600\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     6.1943 Validation Accuracy: 0.111000\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     4.4776 Validation Accuracy: 0.145800\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     3.6756 Validation Accuracy: 0.125000\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     3.5264 Validation Accuracy: 0.101200\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     2.8955 Validation Accuracy: 0.138000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     2.9257 Validation Accuracy: 0.129800\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     2.7197 Validation Accuracy: 0.160400\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     2.6972 Validation Accuracy: 0.147000\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     2.6160 Validation Accuracy: 0.157600\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     2.5923 Validation Accuracy: 0.163200\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     2.6030 Validation Accuracy: 0.158200\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     2.5873 Validation Accuracy: 0.154800\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     2.5652 Validation Accuracy: 0.151400\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     2.5234 Validation Accuracy: 0.150000\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     2.5022 Validation Accuracy: 0.155400\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     2.4933 Validation Accuracy: 0.158400\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     2.4710 Validation Accuracy: 0.158800\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     2.4734 Validation Accuracy: 0.156400\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     2.5271 Validation Accuracy: 0.161400\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     2.8028 Validation Accuracy: 0.146200\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     3.4121 Validation Accuracy: 0.109600\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     7.1630 Validation Accuracy: 0.099800\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     6.5929 Validation Accuracy: 0.100600\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     8.1926 Validation Accuracy: 0.142000\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     9.0348 Validation Accuracy: 0.135800\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     5.0313 Validation Accuracy: 0.136200\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     5.6142 Validation Accuracy: 0.108800\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     4.5433 Validation Accuracy: 0.112600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     3.1517 Validation Accuracy: 0.134400\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     3.0736 Validation Accuracy: 0.128000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     2.7725 Validation Accuracy: 0.151600\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     2.7478 Validation Accuracy: 0.153800\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     2.5947 Validation Accuracy: 0.158800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     2.5503 Validation Accuracy: 0.161800\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     2.5345 Validation Accuracy: 0.158600\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     2.5014 Validation Accuracy: 0.156200\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     2.5060 Validation Accuracy: 0.155400\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     2.5644 Validation Accuracy: 0.153600\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     2.6150 Validation Accuracy: 0.155200\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     2.6278 Validation Accuracy: 0.150200\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     2.7004 Validation Accuracy: 0.145400\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     2.5870 Validation Accuracy: 0.148000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     2.5230 Validation Accuracy: 0.143800\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     2.5201 Validation Accuracy: 0.160800\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     2.4699 Validation Accuracy: 0.163000\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     2.4768 Validation Accuracy: 0.151600\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     2.4606 Validation Accuracy: 0.153600\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     2.6808 Validation Accuracy: 0.145400\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     6.1054 Validation Accuracy: 0.100400\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     8.4952 Validation Accuracy: 0.109000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     7.9283 Validation Accuracy: 0.109200\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     6.4374 Validation Accuracy: 0.113000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     4.6392 Validation Accuracy: 0.117400\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     4.7423 Validation Accuracy: 0.116600\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     3.9998 Validation Accuracy: 0.117000\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     3.5670 Validation Accuracy: 0.147600\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     3.1432 Validation Accuracy: 0.140800\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     2.7112 Validation Accuracy: 0.151600\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     2.6086 Validation Accuracy: 0.156600\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     2.5596 Validation Accuracy: 0.162200\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     2.5563 Validation Accuracy: 0.158200\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     2.5143 Validation Accuracy: 0.162000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     2.5048 Validation Accuracy: 0.158200\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     2.5745 Validation Accuracy: 0.155400\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     2.6168 Validation Accuracy: 0.152000\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     2.6498 Validation Accuracy: 0.158400\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     2.6464 Validation Accuracy: 0.152400\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     2.7733 Validation Accuracy: 0.139600\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     2.6200 Validation Accuracy: 0.131400\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     2.7182 Validation Accuracy: 0.155000\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     3.0140 Validation Accuracy: 0.134800\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     5.6710 Validation Accuracy: 0.138600\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     5.6296 Validation Accuracy: 0.100600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     7.2295 Validation Accuracy: 0.110200\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     7.3870 Validation Accuracy: 0.106400\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     8.4183 Validation Accuracy: 0.100000\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     4.0538 Validation Accuracy: 0.109200\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     3.3140 Validation Accuracy: 0.156400\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     2.9929 Validation Accuracy: 0.107600\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     2.6764 Validation Accuracy: 0.156000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     2.6793 Validation Accuracy: 0.158600\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     2.6708 Validation Accuracy: 0.163400\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     2.6345 Validation Accuracy: 0.163200\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     2.6093 Validation Accuracy: 0.164800\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     2.5890 Validation Accuracy: 0.160600\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     2.5614 Validation Accuracy: 0.165400\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     2.5506 Validation Accuracy: 0.160200\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     2.5749 Validation Accuracy: 0.157400\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     2.5973 Validation Accuracy: 0.155800\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     2.5832 Validation Accuracy: 0.154200\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     2.5703 Validation Accuracy: 0.154800\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     2.5759 Validation Accuracy: 0.157000\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     2.5927 Validation Accuracy: 0.160000\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     2.6162 Validation Accuracy: 0.159200\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     2.9107 Validation Accuracy: 0.142400\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     3.4404 Validation Accuracy: 0.106600\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     4.9511 Validation Accuracy: 0.112200\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     5.9873 Validation Accuracy: 0.152400\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     3.6638 Validation Accuracy: 0.132200\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     3.5578 Validation Accuracy: 0.134000\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     3.0673 Validation Accuracy: 0.140800\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     3.0985 Validation Accuracy: 0.155400\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     2.9447 Validation Accuracy: 0.142800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     2.6461 Validation Accuracy: 0.152400\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     2.9851 Validation Accuracy: 0.140600\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     2.6769 Validation Accuracy: 0.138000\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     2.4407 Validation Accuracy: 0.162800\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     2.4181 Validation Accuracy: 0.167600\n",
      "Epoch 501, CIFAR-10 Batch 1:  Loss:     2.4383 Validation Accuracy: 0.160200\n",
      "Epoch 502, CIFAR-10 Batch 1:  Loss:     2.4949 Validation Accuracy: 0.155400\n",
      "Epoch 503, CIFAR-10 Batch 1:  Loss:     2.5980 Validation Accuracy: 0.151000\n",
      "Epoch 504, CIFAR-10 Batch 1:  Loss:     2.5980 Validation Accuracy: 0.151600\n",
      "Epoch 505, CIFAR-10 Batch 1:  Loss:     2.5802 Validation Accuracy: 0.153400\n",
      "Epoch 506, CIFAR-10 Batch 1:  Loss:     2.6172 Validation Accuracy: 0.147200\n",
      "Epoch 507, CIFAR-10 Batch 1:  Loss:     2.9200 Validation Accuracy: 0.141000\n",
      "Epoch 508, CIFAR-10 Batch 1:  Loss:     4.0469 Validation Accuracy: 0.145200\n",
      "Epoch 509, CIFAR-10 Batch 1:  Loss:     6.4688 Validation Accuracy: 0.110600\n",
      "Epoch 510, CIFAR-10 Batch 1:  Loss:     9.4093 Validation Accuracy: 0.111800\n",
      "Epoch 511, CIFAR-10 Batch 1:  Loss:     7.1877 Validation Accuracy: 0.115400\n",
      "Epoch 512, CIFAR-10 Batch 1:  Loss:     3.9569 Validation Accuracy: 0.133800\n",
      "Epoch 513, CIFAR-10 Batch 1:  Loss:     4.4474 Validation Accuracy: 0.119400\n",
      "Epoch 514, CIFAR-10 Batch 1:  Loss:     2.9613 Validation Accuracy: 0.148000\n",
      "Epoch 515, CIFAR-10 Batch 1:  Loss:     2.8883 Validation Accuracy: 0.133000\n",
      "Epoch 516, CIFAR-10 Batch 1:  Loss:     2.7624 Validation Accuracy: 0.149000\n",
      "Epoch 517, CIFAR-10 Batch 1:  Loss:     2.6734 Validation Accuracy: 0.152600\n",
      "Epoch 518, CIFAR-10 Batch 1:  Loss:     2.5825 Validation Accuracy: 0.163800\n",
      "Epoch 519, CIFAR-10 Batch 1:  Loss:     2.5343 Validation Accuracy: 0.154400\n",
      "Epoch 520, CIFAR-10 Batch 1:  Loss:     2.5088 Validation Accuracy: 0.157600\n",
      "Epoch 521, CIFAR-10 Batch 1:  Loss:     2.4806 Validation Accuracy: 0.154600\n",
      "Epoch 522, CIFAR-10 Batch 1:  Loss:     2.4737 Validation Accuracy: 0.156800\n",
      "Epoch 523, CIFAR-10 Batch 1:  Loss:     2.4554 Validation Accuracy: 0.156200\n",
      "Epoch 524, CIFAR-10 Batch 1:  Loss:     2.4412 Validation Accuracy: 0.159200\n",
      "Epoch 525, CIFAR-10 Batch 1:  Loss:     2.4285 Validation Accuracy: 0.159400\n",
      "Epoch 526, CIFAR-10 Batch 1:  Loss:     2.4157 Validation Accuracy: 0.159400\n",
      "Epoch 527, CIFAR-10 Batch 1:  Loss:     2.4098 Validation Accuracy: 0.158200\n",
      "Epoch 528, CIFAR-10 Batch 1:  Loss:     2.4107 Validation Accuracy: 0.159600\n",
      "Epoch 529, CIFAR-10 Batch 1:  Loss:     2.4306 Validation Accuracy: 0.157000\n",
      "Epoch 530, CIFAR-10 Batch 1:  Loss:     2.4469 Validation Accuracy: 0.152600\n",
      "Epoch 531, CIFAR-10 Batch 1:  Loss:     2.4383 Validation Accuracy: 0.155200\n",
      "Epoch 532, CIFAR-10 Batch 1:  Loss:     2.4269 Validation Accuracy: 0.155800\n",
      "Epoch 533, CIFAR-10 Batch 1:  Loss:     2.4220 Validation Accuracy: 0.163600\n",
      "Epoch 534, CIFAR-10 Batch 1:  Loss:     2.4292 Validation Accuracy: 0.156800\n",
      "Epoch 535, CIFAR-10 Batch 1:  Loss:     2.3889 Validation Accuracy: 0.159800\n",
      "Epoch 536, CIFAR-10 Batch 1:  Loss:     2.4022 Validation Accuracy: 0.151400\n",
      "Epoch 537, CIFAR-10 Batch 1:  Loss:     2.5406 Validation Accuracy: 0.118600\n",
      "Epoch 538, CIFAR-10 Batch 1:  Loss:     2.6958 Validation Accuracy: 0.101200\n",
      "Epoch 539, CIFAR-10 Batch 1:  Loss:     3.0303 Validation Accuracy: 0.126000\n",
      "Epoch 540, CIFAR-10 Batch 1:  Loss:     4.0426 Validation Accuracy: 0.120600\n",
      "Epoch 541, CIFAR-10 Batch 1:  Loss:     3.5873 Validation Accuracy: 0.135000\n",
      "Epoch 542, CIFAR-10 Batch 1:  Loss:     4.6159 Validation Accuracy: 0.133600\n",
      "Epoch 543, CIFAR-10 Batch 1:  Loss:     4.1129 Validation Accuracy: 0.099000\n",
      "Epoch 544, CIFAR-10 Batch 1:  Loss:     3.4125 Validation Accuracy: 0.144800\n",
      "Epoch 545, CIFAR-10 Batch 1:  Loss:     2.8105 Validation Accuracy: 0.157000\n",
      "Epoch 546, CIFAR-10 Batch 1:  Loss:     3.1596 Validation Accuracy: 0.138000\n",
      "Epoch 547, CIFAR-10 Batch 1:  Loss:     3.0451 Validation Accuracy: 0.151000\n",
      "Epoch 548, CIFAR-10 Batch 1:  Loss:     2.6590 Validation Accuracy: 0.155400\n",
      "Epoch 549, CIFAR-10 Batch 1:  Loss:     2.6506 Validation Accuracy: 0.156200\n",
      "Epoch 550, CIFAR-10 Batch 1:  Loss:     2.4733 Validation Accuracy: 0.160800\n",
      "Epoch 551, CIFAR-10 Batch 1:  Loss:     2.4513 Validation Accuracy: 0.148400\n",
      "Epoch 552, CIFAR-10 Batch 1:  Loss:     2.4439 Validation Accuracy: 0.151200\n",
      "Epoch 553, CIFAR-10 Batch 1:  Loss:     2.4321 Validation Accuracy: 0.157400\n",
      "Epoch 554, CIFAR-10 Batch 1:  Loss:     2.4199 Validation Accuracy: 0.160200\n",
      "Epoch 555, CIFAR-10 Batch 1:  Loss:     2.4240 Validation Accuracy: 0.158000\n",
      "Epoch 556, CIFAR-10 Batch 1:  Loss:     2.4397 Validation Accuracy: 0.157800\n",
      "Epoch 557, CIFAR-10 Batch 1:  Loss:     2.4535 Validation Accuracy: 0.156400\n",
      "Epoch 558, CIFAR-10 Batch 1:  Loss:     2.4575 Validation Accuracy: 0.155400\n",
      "Epoch 559, CIFAR-10 Batch 1:  Loss:     2.4600 Validation Accuracy: 0.156400\n",
      "Epoch 560, CIFAR-10 Batch 1:  Loss:     2.4678 Validation Accuracy: 0.155000\n",
      "Epoch 561, CIFAR-10 Batch 1:  Loss:     2.4782 Validation Accuracy: 0.153400\n",
      "Epoch 562, CIFAR-10 Batch 1:  Loss:     2.4763 Validation Accuracy: 0.153400\n",
      "Epoch 563, CIFAR-10 Batch 1:  Loss:     2.4700 Validation Accuracy: 0.154200\n",
      "Epoch 564, CIFAR-10 Batch 1:  Loss:     2.4752 Validation Accuracy: 0.156200\n",
      "Epoch 565, CIFAR-10 Batch 1:  Loss:     2.5012 Validation Accuracy: 0.153600\n",
      "Epoch 566, CIFAR-10 Batch 1:  Loss:     2.4969 Validation Accuracy: 0.152600\n",
      "Epoch 567, CIFAR-10 Batch 1:  Loss:     2.5242 Validation Accuracy: 0.153200\n",
      "Epoch 568, CIFAR-10 Batch 1:  Loss:     2.5206 Validation Accuracy: 0.148000\n",
      "Epoch 569, CIFAR-10 Batch 1:  Loss:     2.5118 Validation Accuracy: 0.146800\n",
      "Epoch 570, CIFAR-10 Batch 1:  Loss:     2.5123 Validation Accuracy: 0.150200\n",
      "Epoch 571, CIFAR-10 Batch 1:  Loss:     2.4562 Validation Accuracy: 0.158200\n",
      "Epoch 572, CIFAR-10 Batch 1:  Loss:     2.4166 Validation Accuracy: 0.159800\n",
      "Epoch 573, CIFAR-10 Batch 1:  Loss:     2.4325 Validation Accuracy: 0.146400\n",
      "Epoch 574, CIFAR-10 Batch 1:  Loss:     2.4242 Validation Accuracy: 0.149600\n",
      "Epoch 575, CIFAR-10 Batch 1:  Loss:     2.4399 Validation Accuracy: 0.110800\n",
      "Epoch 576, CIFAR-10 Batch 1:  Loss:     2.5344 Validation Accuracy: 0.161600\n",
      "Epoch 577, CIFAR-10 Batch 1:  Loss:     2.6350 Validation Accuracy: 0.155600\n",
      "Epoch 578, CIFAR-10 Batch 1:  Loss:     3.3746 Validation Accuracy: 0.100200\n",
      "Epoch 579, CIFAR-10 Batch 1:  Loss:     4.6083 Validation Accuracy: 0.099200\n",
      "Epoch 580, CIFAR-10 Batch 1:  Loss:     5.2307 Validation Accuracy: 0.100800\n",
      "Epoch 581, CIFAR-10 Batch 1:  Loss:     4.6912 Validation Accuracy: 0.116200\n",
      "Epoch 582, CIFAR-10 Batch 1:  Loss:     4.0602 Validation Accuracy: 0.157200\n",
      "Epoch 583, CIFAR-10 Batch 1:  Loss:     3.1819 Validation Accuracy: 0.139000\n",
      "Epoch 584, CIFAR-10 Batch 1:  Loss:     2.6514 Validation Accuracy: 0.148800\n",
      "Epoch 585, CIFAR-10 Batch 1:  Loss:     2.5020 Validation Accuracy: 0.153200\n",
      "Epoch 586, CIFAR-10 Batch 1:  Loss:     2.4597 Validation Accuracy: 0.157400\n",
      "Epoch 587, CIFAR-10 Batch 1:  Loss:     2.4401 Validation Accuracy: 0.165200\n",
      "Epoch 588, CIFAR-10 Batch 1:  Loss:     2.4303 Validation Accuracy: 0.160200\n",
      "Epoch 589, CIFAR-10 Batch 1:  Loss:     2.4027 Validation Accuracy: 0.161600\n",
      "Epoch 590, CIFAR-10 Batch 1:  Loss:     2.3978 Validation Accuracy: 0.158800\n",
      "Epoch 591, CIFAR-10 Batch 1:  Loss:     2.3843 Validation Accuracy: 0.156800\n",
      "Epoch 592, CIFAR-10 Batch 1:  Loss:     2.3926 Validation Accuracy: 0.157800\n",
      "Epoch 593, CIFAR-10 Batch 1:  Loss:     2.3978 Validation Accuracy: 0.150600\n",
      "Epoch 594, CIFAR-10 Batch 1:  Loss:     2.3852 Validation Accuracy: 0.141400\n",
      "Epoch 595, CIFAR-10 Batch 1:  Loss:     2.3805 Validation Accuracy: 0.159400\n",
      "Epoch 596, CIFAR-10 Batch 1:  Loss:     2.3648 Validation Accuracy: 0.163800\n",
      "Epoch 597, CIFAR-10 Batch 1:  Loss:     2.3489 Validation Accuracy: 0.165000\n",
      "Epoch 598, CIFAR-10 Batch 1:  Loss:     2.3452 Validation Accuracy: 0.161400\n",
      "Epoch 599, CIFAR-10 Batch 1:  Loss:     2.3870 Validation Accuracy: 0.158200\n",
      "Epoch 600, CIFAR-10 Batch 1:  Loss:     2.4173 Validation Accuracy: 0.155600\n",
      "Epoch 601, CIFAR-10 Batch 1:  Loss:     2.4026 Validation Accuracy: 0.150000\n",
      "Epoch 602, CIFAR-10 Batch 1:  Loss:     2.3987 Validation Accuracy: 0.157200\n",
      "Epoch 603, CIFAR-10 Batch 1:  Loss:     2.4173 Validation Accuracy: 0.160200\n",
      "Epoch 604, CIFAR-10 Batch 1:  Loss:     2.3696 Validation Accuracy: 0.162000\n",
      "Epoch 605, CIFAR-10 Batch 1:  Loss:     2.3939 Validation Accuracy: 0.152000\n",
      "Epoch 606, CIFAR-10 Batch 1:  Loss:     2.4538 Validation Accuracy: 0.158000\n",
      "Epoch 607, CIFAR-10 Batch 1:  Loss:     2.4767 Validation Accuracy: 0.148400\n",
      "Epoch 608, CIFAR-10 Batch 1:  Loss:     2.5450 Validation Accuracy: 0.154600\n",
      "Epoch 609, CIFAR-10 Batch 1:  Loss:     2.4139 Validation Accuracy: 0.144800\n",
      "Epoch 610, CIFAR-10 Batch 1:  Loss:     2.4241 Validation Accuracy: 0.119400\n",
      "Epoch 611, CIFAR-10 Batch 1:  Loss:     2.3732 Validation Accuracy: 0.144000\n",
      "Epoch 612, CIFAR-10 Batch 1:  Loss:     2.3081 Validation Accuracy: 0.163400\n",
      "Epoch 613, CIFAR-10 Batch 1:  Loss:     2.2911 Validation Accuracy: 0.166800\n",
      "Epoch 614, CIFAR-10 Batch 1:  Loss:     2.2808 Validation Accuracy: 0.173200\n",
      "Epoch 615, CIFAR-10 Batch 1:  Loss:     2.2769 Validation Accuracy: 0.164200\n",
      "Epoch 616, CIFAR-10 Batch 1:  Loss:     2.2788 Validation Accuracy: 0.155000\n",
      "Epoch 617, CIFAR-10 Batch 1:  Loss:     2.2766 Validation Accuracy: 0.163800\n",
      "Epoch 618, CIFAR-10 Batch 1:  Loss:     2.2791 Validation Accuracy: 0.151800\n",
      "Epoch 619, CIFAR-10 Batch 1:  Loss:     2.2755 Validation Accuracy: 0.156800\n",
      "Epoch 620, CIFAR-10 Batch 1:  Loss:     2.2780 Validation Accuracy: 0.155600\n",
      "Epoch 621, CIFAR-10 Batch 1:  Loss:     2.2788 Validation Accuracy: 0.158400\n",
      "Epoch 622, CIFAR-10 Batch 1:  Loss:     2.2803 Validation Accuracy: 0.158200\n",
      "Epoch 623, CIFAR-10 Batch 1:  Loss:     2.2808 Validation Accuracy: 0.159600\n",
      "Epoch 624, CIFAR-10 Batch 1:  Loss:     2.2762 Validation Accuracy: 0.165200\n",
      "Epoch 625, CIFAR-10 Batch 1:  Loss:     2.2750 Validation Accuracy: 0.156800\n",
      "Epoch 626, CIFAR-10 Batch 1:  Loss:     2.2749 Validation Accuracy: 0.164400\n",
      "Epoch 627, CIFAR-10 Batch 1:  Loss:     2.2926 Validation Accuracy: 0.158800\n",
      "Epoch 628, CIFAR-10 Batch 1:  Loss:     2.2946 Validation Accuracy: 0.165200\n",
      "Epoch 629, CIFAR-10 Batch 1:  Loss:     2.2968 Validation Accuracy: 0.153400\n",
      "Epoch 630, CIFAR-10 Batch 1:  Loss:     2.3668 Validation Accuracy: 0.145800\n",
      "Epoch 631, CIFAR-10 Batch 1:  Loss:     2.3274 Validation Accuracy: 0.161800\n",
      "Epoch 632, CIFAR-10 Batch 1:  Loss:     2.3039 Validation Accuracy: 0.154400\n",
      "Epoch 633, CIFAR-10 Batch 1:  Loss:     2.3436 Validation Accuracy: 0.159800\n",
      "Epoch 634, CIFAR-10 Batch 1:  Loss:     2.4772 Validation Accuracy: 0.157600\n",
      "Epoch 635, CIFAR-10 Batch 1:  Loss:     3.3721 Validation Accuracy: 0.119800\n",
      "Epoch 636, CIFAR-10 Batch 1:  Loss:     5.7371 Validation Accuracy: 0.103000\n",
      "Epoch 637, CIFAR-10 Batch 1:  Loss:     7.6729 Validation Accuracy: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638, CIFAR-10 Batch 1:  Loss:     5.2339 Validation Accuracy: 0.106200\n",
      "Epoch 639, CIFAR-10 Batch 1:  Loss:     3.5326 Validation Accuracy: 0.118200\n",
      "Epoch 640, CIFAR-10 Batch 1:  Loss:     3.0855 Validation Accuracy: 0.137600\n",
      "Epoch 641, CIFAR-10 Batch 1:  Loss:     2.7538 Validation Accuracy: 0.127000\n",
      "Epoch 642, CIFAR-10 Batch 1:  Loss:     2.5433 Validation Accuracy: 0.168600\n",
      "Epoch 643, CIFAR-10 Batch 1:  Loss:     2.4330 Validation Accuracy: 0.169800\n",
      "Epoch 644, CIFAR-10 Batch 1:  Loss:     2.4207 Validation Accuracy: 0.155600\n",
      "Epoch 645, CIFAR-10 Batch 1:  Loss:     2.3809 Validation Accuracy: 0.159800\n",
      "Epoch 646, CIFAR-10 Batch 1:  Loss:     2.3853 Validation Accuracy: 0.160800\n",
      "Epoch 647, CIFAR-10 Batch 1:  Loss:     2.3887 Validation Accuracy: 0.164400\n",
      "Epoch 648, CIFAR-10 Batch 1:  Loss:     2.3808 Validation Accuracy: 0.166600\n",
      "Epoch 649, CIFAR-10 Batch 1:  Loss:     2.3803 Validation Accuracy: 0.165600\n",
      "Epoch 650, CIFAR-10 Batch 1:  Loss:     2.3650 Validation Accuracy: 0.166400\n",
      "Epoch 651, CIFAR-10 Batch 1:  Loss:     2.3528 Validation Accuracy: 0.168000\n",
      "Epoch 652, CIFAR-10 Batch 1:  Loss:     2.3514 Validation Accuracy: 0.166600\n",
      "Epoch 653, CIFAR-10 Batch 1:  Loss:     2.3546 Validation Accuracy: 0.162800\n",
      "Epoch 654, CIFAR-10 Batch 1:  Loss:     2.3557 Validation Accuracy: 0.160600\n",
      "Epoch 655, CIFAR-10 Batch 1:  Loss:     2.3503 Validation Accuracy: 0.157800\n",
      "Epoch 656, CIFAR-10 Batch 1:  Loss:     2.3484 Validation Accuracy: 0.159200\n",
      "Epoch 657, CIFAR-10 Batch 1:  Loss:     2.3563 Validation Accuracy: 0.160600\n",
      "Epoch 658, CIFAR-10 Batch 1:  Loss:     2.3634 Validation Accuracy: 0.158600\n",
      "Epoch 659, CIFAR-10 Batch 1:  Loss:     2.3638 Validation Accuracy: 0.159600\n",
      "Epoch 660, CIFAR-10 Batch 1:  Loss:     2.3638 Validation Accuracy: 0.158400\n",
      "Epoch 661, CIFAR-10 Batch 1:  Loss:     2.3690 Validation Accuracy: 0.158000\n",
      "Epoch 662, CIFAR-10 Batch 1:  Loss:     2.3762 Validation Accuracy: 0.153400\n",
      "Epoch 663, CIFAR-10 Batch 1:  Loss:     2.3799 Validation Accuracy: 0.151800\n",
      "Epoch 664, CIFAR-10 Batch 1:  Loss:     2.3631 Validation Accuracy: 0.147800\n",
      "Epoch 665, CIFAR-10 Batch 1:  Loss:     2.3384 Validation Accuracy: 0.141800\n",
      "Epoch 666, CIFAR-10 Batch 1:  Loss:     2.3483 Validation Accuracy: 0.156200\n",
      "Epoch 667, CIFAR-10 Batch 1:  Loss:     2.3279 Validation Accuracy: 0.167400\n",
      "Epoch 668, CIFAR-10 Batch 1:  Loss:     2.3347 Validation Accuracy: 0.156200\n",
      "Epoch 669, CIFAR-10 Batch 1:  Loss:     2.3213 Validation Accuracy: 0.164600\n",
      "Epoch 670, CIFAR-10 Batch 1:  Loss:     2.3241 Validation Accuracy: 0.162800\n",
      "Epoch 671, CIFAR-10 Batch 1:  Loss:     2.3772 Validation Accuracy: 0.166200\n",
      "Epoch 672, CIFAR-10 Batch 1:  Loss:     2.2806 Validation Accuracy: 0.165600\n",
      "Epoch 673, CIFAR-10 Batch 1:  Loss:     2.3322 Validation Accuracy: 0.165000\n",
      "Epoch 674, CIFAR-10 Batch 1:  Loss:     2.2754 Validation Accuracy: 0.156600\n",
      "Epoch 675, CIFAR-10 Batch 1:  Loss:     2.2671 Validation Accuracy: 0.169400\n",
      "Epoch 676, CIFAR-10 Batch 1:  Loss:     2.2811 Validation Accuracy: 0.164400\n",
      "Epoch 677, CIFAR-10 Batch 1:  Loss:     2.2809 Validation Accuracy: 0.159000\n",
      "Epoch 678, CIFAR-10 Batch 1:  Loss:     2.3045 Validation Accuracy: 0.166000\n",
      "Epoch 679, CIFAR-10 Batch 1:  Loss:     2.3004 Validation Accuracy: 0.163000\n",
      "Epoch 680, CIFAR-10 Batch 1:  Loss:     2.3467 Validation Accuracy: 0.167600\n",
      "Epoch 681, CIFAR-10 Batch 1:  Loss:     2.5241 Validation Accuracy: 0.148200\n",
      "Epoch 682, CIFAR-10 Batch 1:  Loss:     2.8534 Validation Accuracy: 0.147800\n",
      "Epoch 683, CIFAR-10 Batch 1:  Loss:     5.6994 Validation Accuracy: 0.128000\n",
      "Epoch 684, CIFAR-10 Batch 1:  Loss:     4.8235 Validation Accuracy: 0.131000\n",
      "Epoch 685, CIFAR-10 Batch 1:  Loss:     5.8668 Validation Accuracy: 0.107400\n",
      "Epoch 686, CIFAR-10 Batch 1:  Loss:     5.3424 Validation Accuracy: 0.098200\n",
      "Epoch 687, CIFAR-10 Batch 1:  Loss:     3.7860 Validation Accuracy: 0.119600\n",
      "Epoch 688, CIFAR-10 Batch 1:  Loss:     3.0337 Validation Accuracy: 0.136600\n",
      "Epoch 689, CIFAR-10 Batch 1:  Loss:     2.6741 Validation Accuracy: 0.158000\n",
      "Epoch 690, CIFAR-10 Batch 1:  Loss:     2.4997 Validation Accuracy: 0.153600\n",
      "Epoch 691, CIFAR-10 Batch 1:  Loss:     2.4092 Validation Accuracy: 0.153600\n",
      "Epoch 692, CIFAR-10 Batch 1:  Loss:     2.3865 Validation Accuracy: 0.155400\n",
      "Epoch 693, CIFAR-10 Batch 1:  Loss:     2.3751 Validation Accuracy: 0.153200\n",
      "Epoch 694, CIFAR-10 Batch 1:  Loss:     2.3634 Validation Accuracy: 0.160000\n",
      "Epoch 695, CIFAR-10 Batch 1:  Loss:     2.3301 Validation Accuracy: 0.166200\n",
      "Epoch 696, CIFAR-10 Batch 1:  Loss:     2.3252 Validation Accuracy: 0.165800\n",
      "Epoch 697, CIFAR-10 Batch 1:  Loss:     2.3306 Validation Accuracy: 0.164400\n",
      "Epoch 698, CIFAR-10 Batch 1:  Loss:     2.3314 Validation Accuracy: 0.164600\n",
      "Epoch 699, CIFAR-10 Batch 1:  Loss:     2.3343 Validation Accuracy: 0.163600\n",
      "Epoch 700, CIFAR-10 Batch 1:  Loss:     2.3345 Validation Accuracy: 0.164600\n",
      "Epoch 701, CIFAR-10 Batch 1:  Loss:     2.3383 Validation Accuracy: 0.165000\n",
      "Epoch 702, CIFAR-10 Batch 1:  Loss:     2.3414 Validation Accuracy: 0.163400\n",
      "Epoch 703, CIFAR-10 Batch 1:  Loss:     2.3388 Validation Accuracy: 0.165400\n",
      "Epoch 704, CIFAR-10 Batch 1:  Loss:     2.3307 Validation Accuracy: 0.167000\n",
      "Epoch 705, CIFAR-10 Batch 1:  Loss:     2.3214 Validation Accuracy: 0.164800\n",
      "Epoch 706, CIFAR-10 Batch 1:  Loss:     2.3146 Validation Accuracy: 0.167200\n",
      "Epoch 707, CIFAR-10 Batch 1:  Loss:     2.3097 Validation Accuracy: 0.167000\n",
      "Epoch 708, CIFAR-10 Batch 1:  Loss:     2.3057 Validation Accuracy: 0.166400\n",
      "Epoch 709, CIFAR-10 Batch 1:  Loss:     2.3022 Validation Accuracy: 0.166800\n",
      "Epoch 710, CIFAR-10 Batch 1:  Loss:     2.2978 Validation Accuracy: 0.166200\n",
      "Epoch 711, CIFAR-10 Batch 1:  Loss:     2.2936 Validation Accuracy: 0.166400\n",
      "Epoch 712, CIFAR-10 Batch 1:  Loss:     2.2897 Validation Accuracy: 0.166600\n",
      "Epoch 713, CIFAR-10 Batch 1:  Loss:     2.2869 Validation Accuracy: 0.165000\n",
      "Epoch 714, CIFAR-10 Batch 1:  Loss:     2.2868 Validation Accuracy: 0.164600\n",
      "Epoch 715, CIFAR-10 Batch 1:  Loss:     2.2865 Validation Accuracy: 0.165000\n",
      "Epoch 716, CIFAR-10 Batch 1:  Loss:     2.2850 Validation Accuracy: 0.163600\n",
      "Epoch 717, CIFAR-10 Batch 1:  Loss:     2.2844 Validation Accuracy: 0.161400\n",
      "Epoch 718, CIFAR-10 Batch 1:  Loss:     2.2859 Validation Accuracy: 0.161600\n",
      "Epoch 719, CIFAR-10 Batch 1:  Loss:     2.2889 Validation Accuracy: 0.162000\n",
      "Epoch 720, CIFAR-10 Batch 1:  Loss:     2.2934 Validation Accuracy: 0.161200\n",
      "Epoch 721, CIFAR-10 Batch 1:  Loss:     2.3001 Validation Accuracy: 0.161800\n",
      "Epoch 722, CIFAR-10 Batch 1:  Loss:     2.3108 Validation Accuracy: 0.161400\n",
      "Epoch 723, CIFAR-10 Batch 1:  Loss:     2.3193 Validation Accuracy: 0.159200\n",
      "Epoch 724, CIFAR-10 Batch 1:  Loss:     2.3268 Validation Accuracy: 0.155800\n",
      "Epoch 725, CIFAR-10 Batch 1:  Loss:     2.3356 Validation Accuracy: 0.153400\n",
      "Epoch 726, CIFAR-10 Batch 1:  Loss:     2.3414 Validation Accuracy: 0.152400\n",
      "Epoch 727, CIFAR-10 Batch 1:  Loss:     2.3393 Validation Accuracy: 0.151200\n",
      "Epoch 728, CIFAR-10 Batch 1:  Loss:     2.3297 Validation Accuracy: 0.154000\n",
      "Epoch 729, CIFAR-10 Batch 1:  Loss:     2.3234 Validation Accuracy: 0.155400\n",
      "Epoch 730, CIFAR-10 Batch 1:  Loss:     2.3272 Validation Accuracy: 0.160400\n",
      "Epoch 731, CIFAR-10 Batch 1:  Loss:     2.3366 Validation Accuracy: 0.157000\n",
      "Epoch 732, CIFAR-10 Batch 1:  Loss:     2.3465 Validation Accuracy: 0.153800\n",
      "Epoch 733, CIFAR-10 Batch 1:  Loss:     2.3388 Validation Accuracy: 0.152000\n",
      "Epoch 734, CIFAR-10 Batch 1:  Loss:     2.3077 Validation Accuracy: 0.149600\n",
      "Epoch 735, CIFAR-10 Batch 1:  Loss:     2.2879 Validation Accuracy: 0.157600\n",
      "Epoch 736, CIFAR-10 Batch 1:  Loss:     2.3231 Validation Accuracy: 0.161800\n",
      "Epoch 737, CIFAR-10 Batch 1:  Loss:     2.3465 Validation Accuracy: 0.150800\n",
      "Epoch 738, CIFAR-10 Batch 1:  Loss:     2.3511 Validation Accuracy: 0.161800\n",
      "Epoch 739, CIFAR-10 Batch 1:  Loss:     2.3358 Validation Accuracy: 0.150200\n",
      "Epoch 740, CIFAR-10 Batch 1:  Loss:     2.3905 Validation Accuracy: 0.160600\n",
      "Epoch 741, CIFAR-10 Batch 1:  Loss:     2.2835 Validation Accuracy: 0.157200\n",
      "Epoch 742, CIFAR-10 Batch 1:  Loss:     2.3630 Validation Accuracy: 0.159800\n",
      "Epoch 743, CIFAR-10 Batch 1:  Loss:     2.2803 Validation Accuracy: 0.153600\n",
      "Epoch 744, CIFAR-10 Batch 1:  Loss:     2.2767 Validation Accuracy: 0.163800\n",
      "Epoch 745, CIFAR-10 Batch 1:  Loss:     2.3063 Validation Accuracy: 0.136200\n",
      "Epoch 746, CIFAR-10 Batch 1:  Loss:     2.2457 Validation Accuracy: 0.160400\n",
      "Epoch 747, CIFAR-10 Batch 1:  Loss:     2.2505 Validation Accuracy: 0.151400\n",
      "Epoch 748, CIFAR-10 Batch 1:  Loss:     2.2394 Validation Accuracy: 0.155400\n",
      "Epoch 749, CIFAR-10 Batch 1:  Loss:     2.2567 Validation Accuracy: 0.161000\n",
      "Epoch 750, CIFAR-10 Batch 1:  Loss:     2.2547 Validation Accuracy: 0.156000\n",
      "Epoch 751, CIFAR-10 Batch 1:  Loss:     2.2481 Validation Accuracy: 0.157800\n",
      "Epoch 752, CIFAR-10 Batch 1:  Loss:     2.2424 Validation Accuracy: 0.159200\n",
      "Epoch 753, CIFAR-10 Batch 1:  Loss:     2.2379 Validation Accuracy: 0.166200\n",
      "Epoch 754, CIFAR-10 Batch 1:  Loss:     2.2402 Validation Accuracy: 0.153600\n",
      "Epoch 755, CIFAR-10 Batch 1:  Loss:     2.2356 Validation Accuracy: 0.166200\n",
      "Epoch 756, CIFAR-10 Batch 1:  Loss:     2.2505 Validation Accuracy: 0.159600\n",
      "Epoch 757, CIFAR-10 Batch 1:  Loss:     2.2579 Validation Accuracy: 0.159400\n",
      "Epoch 758, CIFAR-10 Batch 1:  Loss:     2.2762 Validation Accuracy: 0.167200\n",
      "Epoch 759, CIFAR-10 Batch 1:  Loss:     2.4335 Validation Accuracy: 0.148800\n",
      "Epoch 760, CIFAR-10 Batch 1:  Loss:     3.3520 Validation Accuracy: 0.121600\n",
      "Epoch 761, CIFAR-10 Batch 1:  Loss:     4.5932 Validation Accuracy: 0.113600\n",
      "Epoch 762, CIFAR-10 Batch 1:  Loss:     5.1062 Validation Accuracy: 0.122000\n",
      "Epoch 763, CIFAR-10 Batch 1:  Loss:     5.2258 Validation Accuracy: 0.128600\n",
      "Epoch 764, CIFAR-10 Batch 1:  Loss:     3.4665 Validation Accuracy: 0.110200\n",
      "Epoch 765, CIFAR-10 Batch 1:  Loss:     3.0826 Validation Accuracy: 0.106800\n",
      "Epoch 766, CIFAR-10 Batch 1:  Loss:     2.5880 Validation Accuracy: 0.148800\n",
      "Epoch 767, CIFAR-10 Batch 1:  Loss:     2.5686 Validation Accuracy: 0.147400\n",
      "Epoch 768, CIFAR-10 Batch 1:  Loss:     2.4560 Validation Accuracy: 0.151000\n",
      "Epoch 769, CIFAR-10 Batch 1:  Loss:     2.4382 Validation Accuracy: 0.160000\n",
      "Epoch 770, CIFAR-10 Batch 1:  Loss:     2.3693 Validation Accuracy: 0.163400\n",
      "Epoch 771, CIFAR-10 Batch 1:  Loss:     2.3280 Validation Accuracy: 0.158400\n",
      "Epoch 772, CIFAR-10 Batch 1:  Loss:     2.3363 Validation Accuracy: 0.160200\n",
      "Epoch 773, CIFAR-10 Batch 1:  Loss:     2.3331 Validation Accuracy: 0.159800\n",
      "Epoch 774, CIFAR-10 Batch 1:  Loss:     2.3314 Validation Accuracy: 0.161000\n",
      "Epoch 775, CIFAR-10 Batch 1:  Loss:     2.3198 Validation Accuracy: 0.161800\n",
      "Epoch 776, CIFAR-10 Batch 1:  Loss:     2.3124 Validation Accuracy: 0.162600\n",
      "Epoch 777, CIFAR-10 Batch 1:  Loss:     2.3008 Validation Accuracy: 0.163600\n",
      "Epoch 778, CIFAR-10 Batch 1:  Loss:     2.2938 Validation Accuracy: 0.162800\n",
      "Epoch 779, CIFAR-10 Batch 1:  Loss:     2.2897 Validation Accuracy: 0.161800\n",
      "Epoch 780, CIFAR-10 Batch 1:  Loss:     2.2867 Validation Accuracy: 0.160000\n",
      "Epoch 781, CIFAR-10 Batch 1:  Loss:     2.2867 Validation Accuracy: 0.159600\n",
      "Epoch 782, CIFAR-10 Batch 1:  Loss:     2.2880 Validation Accuracy: 0.159000\n",
      "Epoch 783, CIFAR-10 Batch 1:  Loss:     2.2866 Validation Accuracy: 0.160200\n",
      "Epoch 784, CIFAR-10 Batch 1:  Loss:     2.2851 Validation Accuracy: 0.158600\n",
      "Epoch 785, CIFAR-10 Batch 1:  Loss:     2.2847 Validation Accuracy: 0.160200\n",
      "Epoch 786, CIFAR-10 Batch 1:  Loss:     2.2866 Validation Accuracy: 0.159400\n",
      "Epoch 787, CIFAR-10 Batch 1:  Loss:     2.2917 Validation Accuracy: 0.160800\n",
      "Epoch 788, CIFAR-10 Batch 1:  Loss:     2.2970 Validation Accuracy: 0.159200\n",
      "Epoch 789, CIFAR-10 Batch 1:  Loss:     2.2984 Validation Accuracy: 0.158400\n",
      "Epoch 790, CIFAR-10 Batch 1:  Loss:     2.3002 Validation Accuracy: 0.159400\n",
      "Epoch 791, CIFAR-10 Batch 1:  Loss:     2.3061 Validation Accuracy: 0.158000\n",
      "Epoch 792, CIFAR-10 Batch 1:  Loss:     2.3170 Validation Accuracy: 0.155800\n",
      "Epoch 793, CIFAR-10 Batch 1:  Loss:     2.3268 Validation Accuracy: 0.155000\n",
      "Epoch 794, CIFAR-10 Batch 1:  Loss:     2.3352 Validation Accuracy: 0.153400\n",
      "Epoch 795, CIFAR-10 Batch 1:  Loss:     2.3425 Validation Accuracy: 0.154200\n",
      "Epoch 796, CIFAR-10 Batch 1:  Loss:     2.3471 Validation Accuracy: 0.154800\n",
      "Epoch 797, CIFAR-10 Batch 1:  Loss:     2.3503 Validation Accuracy: 0.154000\n",
      "Epoch 798, CIFAR-10 Batch 1:  Loss:     2.3474 Validation Accuracy: 0.155400\n",
      "Epoch 799, CIFAR-10 Batch 1:  Loss:     2.3487 Validation Accuracy: 0.154600\n",
      "Epoch 800, CIFAR-10 Batch 1:  Loss:     2.3491 Validation Accuracy: 0.155400\n",
      "Epoch 801, CIFAR-10 Batch 1:  Loss:     2.3460 Validation Accuracy: 0.154600\n",
      "Epoch 802, CIFAR-10 Batch 1:  Loss:     2.3417 Validation Accuracy: 0.154400\n",
      "Epoch 803, CIFAR-10 Batch 1:  Loss:     2.3405 Validation Accuracy: 0.155200\n",
      "Epoch 804, CIFAR-10 Batch 1:  Loss:     2.3494 Validation Accuracy: 0.157200\n",
      "Epoch 805, CIFAR-10 Batch 1:  Loss:     2.3621 Validation Accuracy: 0.158200\n",
      "Epoch 806, CIFAR-10 Batch 1:  Loss:     2.3647 Validation Accuracy: 0.155600\n",
      "Epoch 807, CIFAR-10 Batch 1:  Loss:     2.3513 Validation Accuracy: 0.156800\n",
      "Epoch 808, CIFAR-10 Batch 1:  Loss:     2.3372 Validation Accuracy: 0.154400\n",
      "Epoch 809, CIFAR-10 Batch 1:  Loss:     2.3562 Validation Accuracy: 0.154600\n",
      "Epoch 810, CIFAR-10 Batch 1:  Loss:     2.3802 Validation Accuracy: 0.156200\n",
      "Epoch 811, CIFAR-10 Batch 1:  Loss:     2.4155 Validation Accuracy: 0.150000\n",
      "Epoch 812, CIFAR-10 Batch 1:  Loss:     2.3532 Validation Accuracy: 0.149000\n",
      "Epoch 813, CIFAR-10 Batch 1:  Loss:     2.3204 Validation Accuracy: 0.154200\n",
      "Epoch 814, CIFAR-10 Batch 1:  Loss:     2.3426 Validation Accuracy: 0.162200\n",
      "Epoch 815, CIFAR-10 Batch 1:  Loss:     2.3377 Validation Accuracy: 0.157400\n",
      "Epoch 816, CIFAR-10 Batch 1:  Loss:     2.3592 Validation Accuracy: 0.153400\n",
      "Epoch 817, CIFAR-10 Batch 1:  Loss:     2.4012 Validation Accuracy: 0.160200\n",
      "Epoch 818, CIFAR-10 Batch 1:  Loss:     2.3886 Validation Accuracy: 0.147200\n",
      "Epoch 819, CIFAR-10 Batch 1:  Loss:     2.4813 Validation Accuracy: 0.153800\n",
      "Epoch 820, CIFAR-10 Batch 1:  Loss:     2.3383 Validation Accuracy: 0.156800\n",
      "Epoch 821, CIFAR-10 Batch 1:  Loss:     2.3408 Validation Accuracy: 0.151000\n",
      "Epoch 822, CIFAR-10 Batch 1:  Loss:     2.2914 Validation Accuracy: 0.146600\n",
      "Epoch 823, CIFAR-10 Batch 1:  Loss:     2.2750 Validation Accuracy: 0.161200\n",
      "Epoch 824, CIFAR-10 Batch 1:  Loss:     2.2613 Validation Accuracy: 0.154400\n",
      "Epoch 825, CIFAR-10 Batch 1:  Loss:     2.2560 Validation Accuracy: 0.163200\n",
      "Epoch 826, CIFAR-10 Batch 1:  Loss:     2.2620 Validation Accuracy: 0.171000\n",
      "Epoch 827, CIFAR-10 Batch 1:  Loss:     2.2553 Validation Accuracy: 0.164600\n",
      "Epoch 828, CIFAR-10 Batch 1:  Loss:     2.2556 Validation Accuracy: 0.167000\n",
      "Epoch 829, CIFAR-10 Batch 1:  Loss:     2.2526 Validation Accuracy: 0.170000\n",
      "Epoch 830, CIFAR-10 Batch 1:  Loss:     2.2503 Validation Accuracy: 0.171400\n",
      "Epoch 831, CIFAR-10 Batch 1:  Loss:     2.2504 Validation Accuracy: 0.165400\n",
      "Epoch 832, CIFAR-10 Batch 1:  Loss:     2.2495 Validation Accuracy: 0.170400\n",
      "Epoch 833, CIFAR-10 Batch 1:  Loss:     2.2499 Validation Accuracy: 0.161200\n",
      "Epoch 834, CIFAR-10 Batch 1:  Loss:     2.2504 Validation Accuracy: 0.163600\n",
      "Epoch 835, CIFAR-10 Batch 1:  Loss:     2.2513 Validation Accuracy: 0.161600\n",
      "Epoch 836, CIFAR-10 Batch 1:  Loss:     2.2530 Validation Accuracy: 0.160800\n",
      "Epoch 837, CIFAR-10 Batch 1:  Loss:     2.2546 Validation Accuracy: 0.160200\n",
      "Epoch 838, CIFAR-10 Batch 1:  Loss:     2.2576 Validation Accuracy: 0.160000\n",
      "Epoch 839, CIFAR-10 Batch 1:  Loss:     2.2602 Validation Accuracy: 0.158200\n",
      "Epoch 840, CIFAR-10 Batch 1:  Loss:     2.2606 Validation Accuracy: 0.158600\n",
      "Epoch 841, CIFAR-10 Batch 1:  Loss:     2.2615 Validation Accuracy: 0.159000\n",
      "Epoch 842, CIFAR-10 Batch 1:  Loss:     2.2632 Validation Accuracy: 0.153400\n",
      "Epoch 843, CIFAR-10 Batch 1:  Loss:     2.2741 Validation Accuracy: 0.160000\n",
      "Epoch 844, CIFAR-10 Batch 1:  Loss:     2.2477 Validation Accuracy: 0.149600\n",
      "Epoch 845, CIFAR-10 Batch 1:  Loss:     2.3127 Validation Accuracy: 0.149400\n",
      "Epoch 846, CIFAR-10 Batch 1:  Loss:     2.3214 Validation Accuracy: 0.141000\n",
      "Epoch 847, CIFAR-10 Batch 1:  Loss:     2.3831 Validation Accuracy: 0.155800\n",
      "Epoch 848, CIFAR-10 Batch 1:  Loss:     2.6148 Validation Accuracy: 0.122600\n",
      "Epoch 849, CIFAR-10 Batch 1:  Loss:     2.3704 Validation Accuracy: 0.169600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850, CIFAR-10 Batch 1:  Loss:     2.3183 Validation Accuracy: 0.150000\n",
      "Epoch 851, CIFAR-10 Batch 1:  Loss:     2.3169 Validation Accuracy: 0.144200\n",
      "Epoch 852, CIFAR-10 Batch 1:  Loss:     3.0715 Validation Accuracy: 0.150200\n",
      "Epoch 853, CIFAR-10 Batch 1:  Loss:     3.0574 Validation Accuracy: 0.125800\n",
      "Epoch 854, CIFAR-10 Batch 1:  Loss:     4.0780 Validation Accuracy: 0.106400\n",
      "Epoch 855, CIFAR-10 Batch 1:  Loss:     3.4846 Validation Accuracy: 0.142200\n",
      "Epoch 856, CIFAR-10 Batch 1:  Loss:     2.9549 Validation Accuracy: 0.152200\n",
      "Epoch 857, CIFAR-10 Batch 1:  Loss:     2.5224 Validation Accuracy: 0.147200\n",
      "Epoch 858, CIFAR-10 Batch 1:  Loss:     2.3271 Validation Accuracy: 0.150200\n",
      "Epoch 859, CIFAR-10 Batch 1:  Loss:     2.3217 Validation Accuracy: 0.147200\n",
      "Epoch 860, CIFAR-10 Batch 1:  Loss:     2.3070 Validation Accuracy: 0.163200\n",
      "Epoch 861, CIFAR-10 Batch 1:  Loss:     2.2855 Validation Accuracy: 0.164000\n",
      "Epoch 862, CIFAR-10 Batch 1:  Loss:     2.2644 Validation Accuracy: 0.165600\n",
      "Epoch 863, CIFAR-10 Batch 1:  Loss:     2.3205 Validation Accuracy: 0.156600\n",
      "Epoch 864, CIFAR-10 Batch 1:  Loss:     2.3652 Validation Accuracy: 0.152600\n",
      "Epoch 865, CIFAR-10 Batch 1:  Loss:     2.3440 Validation Accuracy: 0.155800\n",
      "Epoch 866, CIFAR-10 Batch 1:  Loss:     2.3433 Validation Accuracy: 0.149400\n",
      "Epoch 867, CIFAR-10 Batch 1:  Loss:     2.3745 Validation Accuracy: 0.149400\n",
      "Epoch 868, CIFAR-10 Batch 1:  Loss:     2.3875 Validation Accuracy: 0.155000\n",
      "Epoch 869, CIFAR-10 Batch 1:  Loss:     2.3700 Validation Accuracy: 0.152800\n",
      "Epoch 870, CIFAR-10 Batch 1:  Loss:     2.3485 Validation Accuracy: 0.149600\n",
      "Epoch 871, CIFAR-10 Batch 1:  Loss:     2.3516 Validation Accuracy: 0.148600\n",
      "Epoch 872, CIFAR-10 Batch 1:  Loss:     2.3759 Validation Accuracy: 0.154400\n",
      "Epoch 873, CIFAR-10 Batch 1:  Loss:     2.4234 Validation Accuracy: 0.154000\n",
      "Epoch 874, CIFAR-10 Batch 1:  Loss:     2.3883 Validation Accuracy: 0.149800\n",
      "Epoch 875, CIFAR-10 Batch 1:  Loss:     2.4045 Validation Accuracy: 0.156600\n",
      "Epoch 876, CIFAR-10 Batch 1:  Loss:     2.3958 Validation Accuracy: 0.150000\n",
      "Epoch 877, CIFAR-10 Batch 1:  Loss:     2.4531 Validation Accuracy: 0.153800\n",
      "Epoch 878, CIFAR-10 Batch 1:  Loss:     2.3456 Validation Accuracy: 0.155200\n",
      "Epoch 879, CIFAR-10 Batch 1:  Loss:     2.3358 Validation Accuracy: 0.158800\n",
      "Epoch 880, CIFAR-10 Batch 1:  Loss:     2.4213 Validation Accuracy: 0.147000\n",
      "Epoch 881, CIFAR-10 Batch 1:  Loss:     2.3723 Validation Accuracy: 0.137800\n",
      "Epoch 882, CIFAR-10 Batch 1:  Loss:     2.2926 Validation Accuracy: 0.159400\n",
      "Epoch 883, CIFAR-10 Batch 1:  Loss:     2.2678 Validation Accuracy: 0.160000\n",
      "Epoch 884, CIFAR-10 Batch 1:  Loss:     2.2502 Validation Accuracy: 0.154800\n",
      "Epoch 885, CIFAR-10 Batch 1:  Loss:     2.3881 Validation Accuracy: 0.154200\n",
      "Epoch 886, CIFAR-10 Batch 1:  Loss:     2.4011 Validation Accuracy: 0.150200\n",
      "Epoch 887, CIFAR-10 Batch 1:  Loss:     2.3880 Validation Accuracy: 0.159600\n",
      "Epoch 888, CIFAR-10 Batch 1:  Loss:     2.5342 Validation Accuracy: 0.134200\n",
      "Epoch 889, CIFAR-10 Batch 1:  Loss:     3.4240 Validation Accuracy: 0.125600\n",
      "Epoch 890, CIFAR-10 Batch 1:  Loss:     2.8228 Validation Accuracy: 0.141000\n",
      "Epoch 891, CIFAR-10 Batch 1:  Loss:     2.9224 Validation Accuracy: 0.120000\n",
      "Epoch 892, CIFAR-10 Batch 1:  Loss:     2.6015 Validation Accuracy: 0.144600\n",
      "Epoch 893, CIFAR-10 Batch 1:  Loss:     2.4441 Validation Accuracy: 0.158000\n",
      "Epoch 894, CIFAR-10 Batch 1:  Loss:     2.4592 Validation Accuracy: 0.151800\n",
      "Epoch 895, CIFAR-10 Batch 1:  Loss:     2.3036 Validation Accuracy: 0.160600\n",
      "Epoch 896, CIFAR-10 Batch 1:  Loss:     2.2810 Validation Accuracy: 0.164000\n",
      "Epoch 897, CIFAR-10 Batch 1:  Loss:     2.2634 Validation Accuracy: 0.159800\n",
      "Epoch 898, CIFAR-10 Batch 1:  Loss:     2.3029 Validation Accuracy: 0.154400\n",
      "Epoch 899, CIFAR-10 Batch 1:  Loss:     2.3056 Validation Accuracy: 0.155000\n",
      "Epoch 900, CIFAR-10 Batch 1:  Loss:     2.3007 Validation Accuracy: 0.156000\n",
      "Epoch 901, CIFAR-10 Batch 1:  Loss:     2.3115 Validation Accuracy: 0.150400\n",
      "Epoch 902, CIFAR-10 Batch 1:  Loss:     2.3853 Validation Accuracy: 0.145400\n",
      "Epoch 903, CIFAR-10 Batch 1:  Loss:     2.3622 Validation Accuracy: 0.146000\n",
      "Epoch 904, CIFAR-10 Batch 1:  Loss:     2.3671 Validation Accuracy: 0.152000\n",
      "Epoch 905, CIFAR-10 Batch 1:  Loss:     2.3321 Validation Accuracy: 0.152600\n",
      "Epoch 906, CIFAR-10 Batch 1:  Loss:     2.3904 Validation Accuracy: 0.151800\n",
      "Epoch 907, CIFAR-10 Batch 1:  Loss:     2.3315 Validation Accuracy: 0.150200\n",
      "Epoch 908, CIFAR-10 Batch 1:  Loss:     2.3466 Validation Accuracy: 0.153200\n",
      "Epoch 909, CIFAR-10 Batch 1:  Loss:     2.3522 Validation Accuracy: 0.149400\n",
      "Epoch 910, CIFAR-10 Batch 1:  Loss:     2.4188 Validation Accuracy: 0.156400\n",
      "Epoch 911, CIFAR-10 Batch 1:  Loss:     2.3393 Validation Accuracy: 0.148000\n",
      "Epoch 912, CIFAR-10 Batch 1:  Loss:     2.3775 Validation Accuracy: 0.156000\n",
      "Epoch 913, CIFAR-10 Batch 1:  Loss:     2.4170 Validation Accuracy: 0.141800\n",
      "Epoch 914, CIFAR-10 Batch 1:  Loss:     2.2707 Validation Accuracy: 0.151200\n",
      "Epoch 915, CIFAR-10 Batch 1:  Loss:     2.3301 Validation Accuracy: 0.157000\n",
      "Epoch 916, CIFAR-10 Batch 1:  Loss:     2.4386 Validation Accuracy: 0.141800\n",
      "Epoch 917, CIFAR-10 Batch 1:  Loss:     2.8346 Validation Accuracy: 0.145200\n",
      "Epoch 918, CIFAR-10 Batch 1:  Loss:     2.5888 Validation Accuracy: 0.148000\n",
      "Epoch 919, CIFAR-10 Batch 1:  Loss:     2.4084 Validation Accuracy: 0.161000\n",
      "Epoch 920, CIFAR-10 Batch 1:  Loss:     2.3465 Validation Accuracy: 0.163200\n",
      "Epoch 921, CIFAR-10 Batch 1:  Loss:     2.2574 Validation Accuracy: 0.161800\n",
      "Epoch 922, CIFAR-10 Batch 1:  Loss:     2.2493 Validation Accuracy: 0.162200\n",
      "Epoch 923, CIFAR-10 Batch 1:  Loss:     2.2603 Validation Accuracy: 0.148600\n",
      "Epoch 924, CIFAR-10 Batch 1:  Loss:     2.2788 Validation Accuracy: 0.159800\n",
      "Epoch 925, CIFAR-10 Batch 1:  Loss:     2.3333 Validation Accuracy: 0.148200\n",
      "Epoch 926, CIFAR-10 Batch 1:  Loss:     2.3775 Validation Accuracy: 0.155600\n",
      "Epoch 927, CIFAR-10 Batch 1:  Loss:     2.3891 Validation Accuracy: 0.149600\n",
      "Epoch 928, CIFAR-10 Batch 1:  Loss:     2.4416 Validation Accuracy: 0.152600\n",
      "Epoch 929, CIFAR-10 Batch 1:  Loss:     2.4992 Validation Accuracy: 0.149800\n",
      "Epoch 930, CIFAR-10 Batch 1:  Loss:     2.5169 Validation Accuracy: 0.145200\n",
      "Epoch 931, CIFAR-10 Batch 1:  Loss:     2.5222 Validation Accuracy: 0.141200\n",
      "Epoch 932, CIFAR-10 Batch 1:  Loss:     2.4482 Validation Accuracy: 0.143200\n",
      "Epoch 933, CIFAR-10 Batch 1:  Loss:     2.3101 Validation Accuracy: 0.156600\n",
      "Epoch 934, CIFAR-10 Batch 1:  Loss:     2.3137 Validation Accuracy: 0.148200\n",
      "Epoch 935, CIFAR-10 Batch 1:  Loss:     2.2806 Validation Accuracy: 0.156200\n",
      "Epoch 936, CIFAR-10 Batch 1:  Loss:     2.3257 Validation Accuracy: 0.151600\n",
      "Epoch 937, CIFAR-10 Batch 1:  Loss:     2.2527 Validation Accuracy: 0.158600\n",
      "Epoch 938, CIFAR-10 Batch 1:  Loss:     2.2247 Validation Accuracy: 0.162400\n",
      "Epoch 939, CIFAR-10 Batch 1:  Loss:     2.2727 Validation Accuracy: 0.154400\n",
      "Epoch 940, CIFAR-10 Batch 1:  Loss:     2.3466 Validation Accuracy: 0.152000\n",
      "Epoch 941, CIFAR-10 Batch 1:  Loss:     2.4435 Validation Accuracy: 0.147800\n",
      "Epoch 942, CIFAR-10 Batch 1:  Loss:     2.3239 Validation Accuracy: 0.150400\n",
      "Epoch 943, CIFAR-10 Batch 1:  Loss:     2.4356 Validation Accuracy: 0.151600\n",
      "Epoch 944, CIFAR-10 Batch 1:  Loss:     2.3528 Validation Accuracy: 0.153600\n",
      "Epoch 945, CIFAR-10 Batch 1:  Loss:     2.3921 Validation Accuracy: 0.151000\n",
      "Epoch 946, CIFAR-10 Batch 1:  Loss:     2.3069 Validation Accuracy: 0.150800\n",
      "Epoch 947, CIFAR-10 Batch 1:  Loss:     2.4527 Validation Accuracy: 0.155400\n",
      "Epoch 948, CIFAR-10 Batch 1:  Loss:     2.5170 Validation Accuracy: 0.147400\n",
      "Epoch 949, CIFAR-10 Batch 1:  Loss:     2.3921 Validation Accuracy: 0.158800\n",
      "Epoch 950, CIFAR-10 Batch 1:  Loss:     2.4419 Validation Accuracy: 0.150000\n",
      "Epoch 951, CIFAR-10 Batch 1:  Loss:     2.3439 Validation Accuracy: 0.164600\n",
      "Epoch 952, CIFAR-10 Batch 1:  Loss:     2.2606 Validation Accuracy: 0.165800\n",
      "Epoch 953, CIFAR-10 Batch 1:  Loss:     2.2988 Validation Accuracy: 0.163000\n",
      "Epoch 954, CIFAR-10 Batch 1:  Loss:     2.3425 Validation Accuracy: 0.143000\n",
      "Epoch 955, CIFAR-10 Batch 1:  Loss:     2.3421 Validation Accuracy: 0.156600\n",
      "Epoch 956, CIFAR-10 Batch 1:  Loss:     2.3577 Validation Accuracy: 0.145400\n",
      "Epoch 957, CIFAR-10 Batch 1:  Loss:     2.3193 Validation Accuracy: 0.146200\n",
      "Epoch 958, CIFAR-10 Batch 1:  Loss:     2.2259 Validation Accuracy: 0.152200\n",
      "Epoch 959, CIFAR-10 Batch 1:  Loss:     2.2888 Validation Accuracy: 0.159600\n",
      "Epoch 960, CIFAR-10 Batch 1:  Loss:     2.3385 Validation Accuracy: 0.148200\n",
      "Epoch 961, CIFAR-10 Batch 1:  Loss:     2.6181 Validation Accuracy: 0.115400\n",
      "Epoch 962, CIFAR-10 Batch 1:  Loss:     2.6690 Validation Accuracy: 0.107400\n",
      "Epoch 963, CIFAR-10 Batch 1:  Loss:     3.0272 Validation Accuracy: 0.148800\n",
      "Epoch 964, CIFAR-10 Batch 1:  Loss:     2.4064 Validation Accuracy: 0.146400\n",
      "Epoch 965, CIFAR-10 Batch 1:  Loss:     2.4254 Validation Accuracy: 0.145400\n",
      "Epoch 966, CIFAR-10 Batch 1:  Loss:     2.3147 Validation Accuracy: 0.161200\n",
      "Epoch 967, CIFAR-10 Batch 1:  Loss:     2.2857 Validation Accuracy: 0.162200\n",
      "Epoch 968, CIFAR-10 Batch 1:  Loss:     2.2767 Validation Accuracy: 0.163000\n",
      "Epoch 969, CIFAR-10 Batch 1:  Loss:     2.2856 Validation Accuracy: 0.160000\n",
      "Epoch 970, CIFAR-10 Batch 1:  Loss:     2.3257 Validation Accuracy: 0.160600\n",
      "Epoch 971, CIFAR-10 Batch 1:  Loss:     2.3277 Validation Accuracy: 0.151600\n",
      "Epoch 972, CIFAR-10 Batch 1:  Loss:     2.3728 Validation Accuracy: 0.154600\n",
      "Epoch 973, CIFAR-10 Batch 1:  Loss:     2.3619 Validation Accuracy: 0.146600\n",
      "Epoch 974, CIFAR-10 Batch 1:  Loss:     2.4486 Validation Accuracy: 0.140200\n",
      "Epoch 975, CIFAR-10 Batch 1:  Loss:     2.7916 Validation Accuracy: 0.122200\n",
      "Epoch 976, CIFAR-10 Batch 1:  Loss:     3.7266 Validation Accuracy: 0.105600\n",
      "Epoch 977, CIFAR-10 Batch 1:  Loss:     2.6512 Validation Accuracy: 0.120000\n",
      "Epoch 978, CIFAR-10 Batch 1:  Loss:     2.4909 Validation Accuracy: 0.164200\n",
      "Epoch 979, CIFAR-10 Batch 1:  Loss:     2.3986 Validation Accuracy: 0.156400\n",
      "Epoch 980, CIFAR-10 Batch 1:  Loss:     2.4219 Validation Accuracy: 0.154400\n",
      "Epoch 981, CIFAR-10 Batch 1:  Loss:     2.2941 Validation Accuracy: 0.154800\n",
      "Epoch 982, CIFAR-10 Batch 1:  Loss:     2.2759 Validation Accuracy: 0.164800\n",
      "Epoch 983, CIFAR-10 Batch 1:  Loss:     2.2541 Validation Accuracy: 0.168800\n",
      "Epoch 984, CIFAR-10 Batch 1:  Loss:     2.2889 Validation Accuracy: 0.165000\n",
      "Epoch 985, CIFAR-10 Batch 1:  Loss:     2.3524 Validation Accuracy: 0.156000\n",
      "Epoch 986, CIFAR-10 Batch 1:  Loss:     2.3948 Validation Accuracy: 0.160200\n",
      "Epoch 987, CIFAR-10 Batch 1:  Loss:     2.4800 Validation Accuracy: 0.153000\n",
      "Epoch 988, CIFAR-10 Batch 1:  Loss:     2.3602 Validation Accuracy: 0.155200\n",
      "Epoch 989, CIFAR-10 Batch 1:  Loss:     2.4222 Validation Accuracy: 0.150800\n",
      "Epoch 990, CIFAR-10 Batch 1:  Loss:     2.3138 Validation Accuracy: 0.149600\n",
      "Epoch 991, CIFAR-10 Batch 1:  Loss:     3.2633 Validation Accuracy: 0.156400\n",
      "Epoch 992, CIFAR-10 Batch 1:  Loss:     2.3938 Validation Accuracy: 0.151400\n",
      "Epoch 993, CIFAR-10 Batch 1:  Loss:     2.3475 Validation Accuracy: 0.158200\n",
      "Epoch 994, CIFAR-10 Batch 1:  Loss:     2.4858 Validation Accuracy: 0.160600\n",
      "Epoch 995, CIFAR-10 Batch 1:  Loss:     2.3490 Validation Accuracy: 0.160800\n",
      "Epoch 996, CIFAR-10 Batch 1:  Loss:     2.2726 Validation Accuracy: 0.167000\n",
      "Epoch 997, CIFAR-10 Batch 1:  Loss:     2.2740 Validation Accuracy: 0.165600\n",
      "Epoch 998, CIFAR-10 Batch 1:  Loss:     2.3702 Validation Accuracy: 0.160600\n",
      "Epoch 999, CIFAR-10 Batch 1:  Loss:     2.3111 Validation Accuracy: 0.153400\n",
      "Epoch 1000, CIFAR-10 Batch 1:  Loss:     2.2715 Validation Accuracy: 0.170800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
